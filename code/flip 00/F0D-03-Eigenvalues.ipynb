{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLIP (00): Data Science \n",
    "**(Module 03: Linear Algebra)**\n",
    "\n",
    "---\n",
    "- Materials in this module include resources collected from various open-source online repositories.\n",
    "- You are free to use,but NOT allowed to change and distribute this package.\n",
    "\n",
    "Prepared by and for \n",
    "**Student Members** |\n",
    "2006-2018 [TULIP Lab](http://www.tulip.org.au), Australia\n",
    "\n",
    "---\n",
    "\n",
    "## Session 11 Eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.size'] = 16\n",
    "rcParams['figure.figsize'] = (12,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\newcommand{\\bx}{\\boldsymbol{x}}\n",
    "$\n",
    "\n",
    "Eigenvalues, $\\lambda$ and their corresponding eigenvectors\n",
    "$\\boldsymbol{u}$ are non-zero solutions to the linear system\n",
    "\n",
    "$$A\\boldsymbol{u} = \\lambda \\boldsymbol{u}.$$\n",
    "\n",
    "Matrix eigenthings often important: e.g. resonant modes of system, or\n",
    "defining spectral radius $\\varrho(M) = \\max | \\lambda(M) |$ which\n",
    "encodes e.g. convergence of iterative schemes for linear systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvalues and polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard definition of eigenvalues: the $n$ roots of the *characteristic\n",
    "polynomial*\n",
    "\n",
    "$$\\det ( A - \\lambda I) = 0.$$\n",
    "\n",
    "Could compute roots e.g. by nonlinear root finding.\n",
    "\n",
    "There are two essential problems with this:\n",
    "\n",
    "1.  Frequently do not need all eigenvalues, but only the largest one(s).\n",
    "    Computing all, and then sorting, excessively expensive.\n",
    "\n",
    "2.  Polynomials may be *badly conditioned*: a small change in the\n",
    "    coefficients leads to a large change in the roots.\n",
    "\n",
    "A $1\\%$ change in the last coefficient leads to massive changes for\n",
    "\n",
    "$$p(z) = -120 + 274 z - 225 z^2 + 85 z^3 -15 z^4 + z^5;$$\n",
    "\n",
    "the roots $(4, 5)$ become $(4.580 \\pm 0.966 \\sqrt{-1})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The power method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to compute largest eigenvalue without relying on characteristic\n",
    "polynomial. Hint from first computer lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta = np.linspace(0.0, 2.0*np.pi)\n",
    "X = np.zeros((5,2,len(theta)))\n",
    "X[0,0,:] = np.cos(theta)\n",
    "X[0,1,:] = np.sin(theta)\n",
    "A = np.random.rand(2,2)\n",
    "for n in range(4):\n",
    "    for i in range(len(theta)):\n",
    "        X[n+1,:,i] = np.dot(A, X[n,:,i])\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(X[0,0,:], X[0,1,:], np.zeros_like(theta), label='Unit circle')\n",
    "ax.plot(X[1,0,:], X[1,1,:], np.zeros_like(theta), label=r\"Circle acted on by $A$\")\n",
    "ax.plot(X[2,0,:], X[2,1,:], np.zeros_like(theta), label=r\"Circle acted on by $A^2$\")\n",
    "ax.plot(X[3,0,:], X[3,1,:], np.zeros_like(theta), label=r\"Circle acted on by $A^3$\")\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The power method: basis vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key to power method: *assumption* that eigenvectors $\\{\n",
    "  {\\boldsymbol{u}}_n \\}$ form a basis of ${\\mathbb C}^n$. If true,\n",
    "repeated action of $A$ on *generic* vector ${\\boldsymbol{x}}$ picks out\n",
    "eigenvector with largest eigenvalue.\n",
    "\n",
    "Specifically, construct sequence of vectors $\\{ \\bx^{(n)}\n",
    "  \\}$. Initial guess $\\bx^{(0)}$ (nearly) arbitrary, members of sequence\n",
    "are\n",
    "\n",
    "$$\\bx^{(k)} = A^k \\bx^{(0)}.$$\n",
    "\n",
    "Writing initial guess in terms of basis of eigenvectors shows\n",
    "\n",
    "$$\\bx^{(0)} = \\sum_{j=1}^n a_j {\\boldsymbol{u}}_j \\, \\implies \\,\n",
    "    \\bx^{(k)} = \\lambda_1^k \\left[ a_1 {\\boldsymbol{u}}_1 + \\left(\n",
    "        \\frac{\\lambda_2}{\\lambda_1} \\right)^{{k}} a_2 {\\boldsymbol{u}}_2 + \\dots + \\left(\n",
    "        \\frac{\\lambda_n}{\\lambda_1} \\right)^{{k}} a_n {\\boldsymbol{u}}_n \\right].$$\n",
    "\n",
    "If $| \\lambda_j / \\lambda_1 | < 1 \\quad \\forall j > 1$ then the first\n",
    "term dominates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caveats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some points have been glossed over:\n",
    "\n",
    "1.  Have assumed *unique* eigenvalue of maximum modulus.\n",
    "\n",
    "2.  Have assumed the eigenvectors exist and are linearly independent.\n",
    "    This is necessary to have a basis of eigenvectors.\n",
    "\n",
    "3.  Have assumed the initial guess $\\bx^{(0)}$ has a nonzero component\n",
    "    in the direction of eigenvector ${\\boldsymbol{u}}_1$; i.e. if\n",
    "\n",
    "    $$\\bx^{(0)} = \\sum_{j=1}^n a_j {\\boldsymbol{u}}_j \\quad \\implies \\quad a_1 \\neq 0.$$\n",
    "\n",
    "    Not a major problem: repeated numerical operations have floating\n",
    "    point error, so $a_1$ will never be *precisely* zero. Method\n",
    "    converges faster the closer that $\\bx^{(0)}$ is aligned with\n",
    "    ${\\boldsymbol{u}}_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can write the iterative method given by the power method as\n",
    "\n",
    "$$\\bx^{(k)} = \\lambda_1^k \\left( a_1 {\\boldsymbol{u}}_1 + \\epsilon^{(k)} \\right)$$\n",
    "\n",
    "where the term\n",
    "\n",
    "$$\\epsilon^{(k)} \\equiv \\sum_{j=2}^n \\left(\n",
    "      \\frac{\\lambda_j}{\\lambda_1} \\right)^k a_j {\\boldsymbol{u}}_j$$\n",
    "\n",
    "is expected to vanish in the limit. Explicitly,\n",
    "\n",
    "$$\\| \\epsilon^{(k)} \\| = {\\cal O} \\left( \\left|\n",
    "       \\frac{\\lambda_j}{\\lambda_1} \\right|^k \\right)\n",
    "   \\xrightarrow[k \\rightarrow \\infty]{} 0.$$\n",
    "\n",
    "In general expect the “error term” at each step to diminish by\n",
    "$|\\lambda_2 / \\lambda_1|$, giving linear convergence, as seen later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest (and not fully correct) algorithm defines the ratio\n",
    "\n",
    "$$r_k = \\frac{\\| \\bx^{(k+1)} \\|}{\\| \\bx^{(k)} \\|} = |\\lambda_1|\n",
    "    \\frac{\\| a_1 {\\boldsymbol{u}}_1 + \\epsilon^{(k+1)} \\|}{\\| a_1 {\\boldsymbol{u}}_1 +\n",
    "      \\epsilon^{(k)} \\|}.$$\n",
    "\n",
    "From the convergence of the “error term” we then have that\n",
    "\n",
    "$$\\lim_{k\\rightarrow\\infty} r_k = | \\lambda_1 |.$$\n",
    "\n",
    "Algorithm is impractical: unless $\\lambda_1$ is *extremely* close to 1,\n",
    "iterates diverge to infinity or zero, spoiling accuracy. Instead\n",
    "redefine members of sequence to have unit norm *after* computing the\n",
    "ratio $r_k$:\n",
    "\n",
    "1.  Pick $\\bx^{(0)}$ such that $\\|\\bx^{(0)}\\|=1$.\n",
    "\n",
    "2.  For each $k$ compute $\\bx^{(k+1)} = A \\bx^{(k)}$.\n",
    "\n",
    "3.  Compute $r_k = \\| \\bx^{(k+1)} \\|$ (as $\\| \\bx^{(k)} \\| = 1$).\n",
    "\n",
    "4.  Re-normalize $\\bx^{(k+1)}$. Repeat from (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core of a simple  script for the power method:\n",
    "\n",
    "    for k = 2 : niterations_max\n",
    "        xn(:,k-1) = xn(:,k-1)./norm(xn(:,k-1));\n",
    "        xn(:,k) = A * xn(:, k-1);\n",
    "        rn(k) = norm(xn(:,k))./norm(xn(:,k-1));\n",
    "        if (abs(rn(k) - rn(k-1)) < tol)\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    lambda = rn(k);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def power_method(A, niterations_max = 50, tol = 1e-15):\n",
    "    xn = np.zeros((len(A), niterations_max+1))\n",
    "    xn[:, 0] = np.ones((len(A),)) + 1e-7*np.random.rand(len(A))\n",
    "    rn = np.ones((niterations_max+1,))\n",
    "    for k in range(niterations_max):\n",
    "        xn[:,k] = xn[:,k] / np.linalg.norm(xn[:,k])\n",
    "        xn[:,k+1] = np.dot(A, xn[:,k])\n",
    "        rn[k+1] = np.linalg.norm(xn[:,k+1])\n",
    "        if (abs(rn[k+1]-rn[k]) < tol): \n",
    "            break\n",
    "    if k < niterations_max:\n",
    "        rn[k+2:] = rn[k+1] # This ensures the later values are set to something sensible.\n",
    "    return (rn[k+1], rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lamda, v = np.linalg.eig(A)\n",
    "lamda_power, lamda_seq = power_method(A)\n",
    "print(\"The maximum eigenvalue from the power method is {} (exact is {}, error is {})\".format(lamda_power, np.max(lamda), \n",
    "                                                                                             abs(lamda_power - np.max(lamda))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errors = np.abs(lamda_seq - np.max(lamda))\n",
    "iterations = range(len(errors))\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.semilogy(iterations, errors, 'kx')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel(r\"$\\|$ Error $\\|$\")\n",
    "ax.set_title(r\"Convergence of the power method, $n=2$\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B = np.random.rand(10,10)\n",
    "lamda, v = np.linalg.eig(B)\n",
    "lamda_power, lamda_seq = power_method(B)\n",
    "print(\"The maximum eigenvalue from the power method is {} (exact is {}, error is {})\".format(lamda_power, np.max(lamda), \n",
    "                                                                                             abs(lamda_power - np.max(lamda))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errors = np.abs(lamda_seq - np.max(lamda))\n",
    "iterations = range(len(errors))\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.semilogy(iterations, errors, 'kx')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel(r\"$\\|$ Error $\\|$\")\n",
    "ax.set_title(r\"Convergence of the power method, $n=10$\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beyond the absolute value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although $\\max |\\lambda|$ useful, straightforward to modify power method\n",
    "to compute actual full value.\n",
    "\n",
    "The eigenvalue is complex (in general), so in computing just the\n",
    "*modulus* have lost information about the *phase*. Phase information\n",
    "lost when norms are computed. So replace the norms with a different\n",
    "*linear* functional $\\phi: {\\mathbb C}^n\n",
    "  \\rightarrow {\\mathbb R}$.\n",
    "\n",
    "Then have\n",
    "\n",
    "$$r_k = \\frac{\\phi(\\bx^{(k+1)})}{\\phi(\\bx^{(k)})} = \\lambda_1\n",
    "    \\frac{ a_1 \\phi({\\boldsymbol{u}}_1) + \\phi(\\epsilon^{(k+1)})}{ a_1 \\phi( {\\boldsymbol{u}}_1) +\n",
    "      \\phi(\\epsilon^{(k)})};$$\n",
    "\n",
    "depends on the linearity of $\\phi$. In the limit get full eigenvalue\n",
    "$\\lambda_1$.\n",
    "\n",
    "One possible choice for $\\phi$ is to simply sum the components of $\\bx$.\n",
    "In all cases care must be taken to avoid dividing by zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the power method to the matrix\n",
    "\n",
    "$$A =\n",
    "        \\begin{pmatrix}\n",
    "          1 & 2 & 3 \\\\\n",
    "          4 & 5 & 6 \\\\\n",
    "          7 & 8 & 0\n",
    "        \\end{pmatrix}.$$\n",
    "\n",
    "The result converges linearly to find $\\lambda = 12.1229$.\n",
    "\n",
    "Identical convergence is seen for $-A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def full_power_method(A, niterations_max=50, tol=1e-15):\n",
    "    xn = np.zeros((len(A), niterations_max+1))\n",
    "    xn[:, 0] = np.ones((len(A),)) + 1e-7*np.random.rand(len(A))\n",
    "    rn = np.ones((niterations_max+1,))\n",
    "    for k in range(niterations_max):\n",
    "        xn[:,k] = xn[:,k] / np.linalg.norm(xn[:,k])\n",
    "        xn[:,k+1] = np.dot(A, xn[:,k])\n",
    "        rn[k+1] = np.sum(xn[:,k+1])/np.sum(xn[:,k])\n",
    "        if (abs(rn[k+1]-rn[k]) < tol):\n",
    "            break\n",
    "    if k < niterations_max:\n",
    "        rn[k+2:] = rn[k+1] # This ensures the later values are set to something sensible.\n",
    "    return (rn[k+1], rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[1.0,2.0,3.0],[4.0,5.0,6.0],[7.0,8.0,0.0]])\n",
    "lamda, v = np.linalg.eig(A)\n",
    "lamda_power, lamda_seq = full_power_method(A)\n",
    "print(\"The maximum eigenvalue from the power method is {} (exact is {}, error is {})\".format(lamda_power, np.max(lamda), \n",
    "                                                                                             abs(lamda_power - np.max(lamda))))\n",
    "lamda, v = np.linalg.eig(-A)\n",
    "lamda_power, lamda_seq = full_power_method(-A)\n",
    "print(\"For -A, maximum eigenvalue from the power method is {} (exact is {}, error is {})\".format(lamda_power, np.min(lamda), \n",
    "                                                                                             abs(lamda_power - np.min(lamda))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errors = np.abs(lamda_seq - np.min(lamda))\n",
    "iterations = range(len(errors))\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.semilogy(iterations, errors, 'kx')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel(r\"$\\|$ Error $\\|$\")\n",
    "ax.set_title(r\"Convergence of the full power method, $n=3$\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate of convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at behaviour near solution using Taylor’s theorem.\n",
    "\n",
    "Start by defining $\\mu = \\lambda_2 / \\lambda_1$. Use as “small\n",
    "parameter” in expansion. Note that\n",
    "\n",
    "$$\\left| \\frac{\\lambda_j}{\\lambda_1} \\right|  < |\\mu| \\quad \\forall\n",
    "    j > 2.$$\n",
    "\n",
    "Rewrite ratio as\n",
    "\n",
    "$$r_k =  \\lambda_1\n",
    "    \\frac{ a_1 \\phi({\\boldsymbol{u}}_1) + \\phi(\\epsilon^{(k+1)})}{ a_1\n",
    "      \\phi( {\\boldsymbol{u}}_1) + \\phi(\\epsilon^{(k)})} = \\lambda_1 \\left[\n",
    "      1 - \\phi (\\epsilon^{(k)}) \\right] + {\\cal O} (\\mu^{k+1}).$$\n",
    "\n",
    "The relative error is then\n",
    "\n",
    "$$E^{(k)} = \\left| \\frac{r_k - \\lambda_1}{\\lambda_1} \\right|    \n",
    "    = \\left| \\phi( \\epsilon^{(k)} ) \\right|  + {\\cal O}\n",
    "    (\\mu^{k+1}) \n",
    "    = c_k \\mu^k.$$\n",
    "\n",
    "Hence we have a linear decrease at each stage of a factor $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix\n",
    "\n",
    "$$A =\n",
    "        \\begin{pmatrix}\n",
    "          1 & 2 & 3 \\\\\n",
    "          4 & 5 & 6 \\\\\n",
    "          7 & 8 & 0\n",
    "        \\end{pmatrix}$$\n",
    "\n",
    "has eigenvalues\n",
    "\n",
    "$$\\left\\{\n",
    "          \\begin{array}{c}\n",
    "            12.1229\\\\ -5.7345\\\\ -0.3884\n",
    "          \\end{array}\\right. .$$\n",
    "\n",
    "Therefore the slope of the line should be $\\log(|\\mu|) \\simeq -0.748593$; the actual best fit line used (carefully excluding endpoints!) had slope $-0.748590$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lamda_sorted = np.sort(np.abs(lamda))\n",
    "slope = np.log(lamda_sorted[-2]/lamda_sorted[-1])\n",
    "\n",
    "p = np.polyfit(iterations[5:35], np.log(errors[5:35]), 1)\n",
    "\n",
    "print(\"Expected slope is {}; measured slope is {}.\".format(slope, p[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.semilogy(iterations, errors, 'kx', label = 'Data')\n",
    "ax.semilogy(iterations, np.exp(np.array(iterations)*p[0]+p[1]), 'b-', label = r\"Best fit, slope {:2f}\".format(p[0]))\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel(r\"$\\|$ Error $\\|$\")\n",
    "ax.set_title(r\"Convergence of the full power method, $n=3$\")\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Eigenvalues of matrices contain fundamental information: we will\n",
    "    frequently want or need to compute them. The eigenvalues of largest\n",
    "    magnitude are frequently important for, e.g. the spectral radius.\n",
    "\n",
    "-   Computing the eigenvalues from the characteristic polynomial may be\n",
    "    numerically ill-conditioned.\n",
    "\n",
    "-   The power method is an iterative scheme for finding the largest\n",
    "    eigenvalue. It assumes that\n",
    "\n",
    "    1.  There is a single largest eigenvalue;\n",
    "\n",
    "    2.  The eigenvectors are linearly independent.\n",
    "\n",
    "-   The power method converges linearly.\n",
    "\n",
    "-   The power method works when there are repeated eigenvalues; the\n",
    "    eigenvector cannot be found, however. With distinct “largest”\n",
    "    eigenvalues it may fail."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
