{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLIP(01):  Advanced Data Science\n",
    "**(Module 02: Machine Learning)**\n",
    "\n",
    "---\n",
    "- Materials in this module include resources collected from various open-source online repositories.\n",
    "- You are free to use, but NOT allowed to change or distribute this package.\n",
    "\n",
    "Prepared by and for \n",
    "**Student Members** |\n",
    "2006-2018 [TULIP Lab](http://www.tulip.org.au)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Session 00 - MLPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "## 1. Pipeline and FeatureUnion: combining estimators\n",
    "\n",
    "### Pipeline: chaining estimators\n",
    "<font color = 'blue'><b>Pipeline</b></font> can be used to chain multiple estimators into one. This is useful as there is often a fixed sequence of steps in processing the data, for example feature selection, normalization and classification. \n",
    "\n",
    "<br/><font color = 'blue'><b>Pipeline</b></font> serves two purposes here:\n",
    "\n",
    "<br/><font size = 2.5><b>Convenience and encapsulation</b></font></br>\n",
    "    <br/><font size = 2>You only have to call fit and predict once on your data to fit a whole sequence of estimators.</br></font>\n",
    "<br/><font size = 2.5><b>Joint parameter selection</b></font></br>\n",
    "    <br/><font size = 2> You can grid search over parameters of all estimators in the pipeline at once.</br></font>    \n",
    "<font size = 2.5><b>Safety</b></font></br>\n",
    "    <br/><font size = 2> Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.</br></font>       \n",
    "\n",
    "<font size = 2>All estimators in a pipeline, except the last one, must be transformers (i.e. must have a transform method). The last estimator may be any type (transformer, classifier, etc.).</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Usage</b>\n",
    "\n",
    "The Pipeline is built using a list of (key, value) pairs, where the key is a string containing the name you want to give this step and value is an estimator object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "estimators = [('reduce_dim', PCA()), ('clf', SVC())]\n",
    "pipe = Pipeline(estimators)\n",
    "pipe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import Binarizer\n",
    "make_pipeline(Binarizer(), MultinomialNB()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimators of a pipeline are stored as a list in the steps attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe.steps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and as a dict in named_steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe.named_steps['reduce_dim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters of the estimators in the pipeline can be accessed using the __ syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe.set_params(clf__C=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes of named_steps map to keys, enabling tab completion in interactive environments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe.named_steps.reduce_dim is pipe.named_steps['reduce_dim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is particularly important for doing grid searches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = dict(reduce_dim__n_components=[2, 5, 10],\n",
    "                  clf__C=[0.1, 10, 100])\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual steps may also be replaced as parameters, and non-final steps may be ignored by setting them to None:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "param_grid = dict(reduce_dim=[None, PCA(5), PCA(10)],\n",
    "                  clf=[SVC(), LogisticRegression()],\n",
    "                  clf__C=[0.1, 10, 100])\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Notes</b>\n",
    "\n",
    "Calling fit on the pipeline is the same as calling fit on each estimator in turn, transform the input and pass it on to the next step. The pipeline has all the methods that the last estimator in the pipeline has, i.e. if the last estimator is a classifier, the Pipeline can be used as a classifier. If the last estimator is a transformer, again, so is the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Caching transformers: avoid repeated computation</b>\n",
    "\n",
    "Fitting transformers may be computationally expensive. With its memory parameter set, <font color = 'blue'>Pipeline</font> will cache each transformer after calling fit. This feature is used to avoid computing the fit transformers within a pipeline if the parameters and input data are identical. A typical example is the case of a grid search in which the transformers can be fitted only once and reused for each configuration.\n",
    "\n",
    "The parameter memory is needed in order to cache the transformers. memory can be either a string containing the directory where to cache the transformers or a <font color = 'blue'>joblib.Memory</font> object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "estimators = [('reduce_dim', PCA()), ('clf', SVC())]\n",
    "cachedir = mkdtemp()\n",
    "pipe = Pipeline(estimators, memory=cachedir)\n",
    "pipe \n",
    "\n",
    "# Clear the cache directory when you don't need it anymore\n",
    "rmtree(cachedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'red'>Warning: Side effect of caching transformers</font>\n",
    "<br/><font color = 'red'>Using a </font>Pipeline <font color = 'red'>without cache enabled, it is possible to inspect the original instance such as:</font></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "pca1 = PCA()\n",
    "svm1 = SVC()\n",
    "pipe = Pipeline([('reduce_dim', pca1), ('clf', svm1)])\n",
    "pipe.fit(digits.data, digits.target)\n",
    "\n",
    "# The pca instance can be inspected directly\n",
    "print(pca1.components_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'red'>Enabling caching triggers a clone of the transformers before fitting. Therefore, the transformer instance given to the pipeline cannot be inspected directly. In following example, accessing the </font>PCA <font color = 'red'>instance </font>pca2 <font color = 'red'>will raise an </font>AttributeError <font color = 'red'>since</font> pca2 <font color = 'red'>will be an unfitted transformer. Instead, use the attribute </font>named_steps <font color = 'red'>to inspect estimators within the pipeline:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cachedir = mkdtemp()\n",
    "pca2 = PCA()\n",
    "svm2 = SVC()\n",
    "cached_pipe = Pipeline([('reduce_dim', pca2), ('clf', svm2)],\n",
    "                       memory=cachedir)\n",
    "cached_pipe.fit(digits.data, digits.target)\n",
    "\n",
    "print(cached_pipe.named_steps['reduce_dim'].components_)\n",
    "\n",
    "# Remove the cache directory\n",
    "rmtree(cachedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. FeatureUnion: composite feature spaces\n",
    "\n",
    "<br/><font color = 'blue'><b>FeatureUnion</b></font> combines several transformer objects into a new transformer that combines their output. A <font color = 'blue'><b>FeatureUnion</b></font> takes a list of transformer objects. During fitting, each of these is fit to the data independently. For transforming data, the transformers are applied in parallel, and the sample vectors they output are concatenated end-to-end into larger vectors.</br>\n",
    "\n",
    "<br/><font color = 'blue'><b>FeatureUnion</b></font> serves the same purposes as <font color = 'blue'><b>Pipeline</b></font> - convenience and joint parameter estimation and validation.\n",
    "\n",
    "<br/><font color = 'blue'><b>FeatureUnion</b></font> and <font color = 'blue'><b>Pipeline</b></font> can be combined to create complex models.\n",
    "\n",
    "(A <font color = 'blue'>FeatureUnion</font>has no way of checking whether two transformers might produce identical features. It only produces a union when the feature sets are disjoint, and making sure they are the caller’s responsibility.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Usage</b>\n",
    "\n",
    "A <font color = 'blue'>FeatureUnion</font> is built using a list of (key, value) pairs, where the key is the name you want to give to a given transformation (an arbitrary string; it only serves as an identifier) and value is an estimator object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "estimators = [('linear_pca', PCA()), ('kernel_pca', KernelPCA())]\n",
    "combined = FeatureUnion(estimators)\n",
    "combined "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like pipelines, feature unions have a shorthand constructor called <font color = 'blue'>make_union</font> that does not require explicit naming of the components.\n",
    "\n",
    "Like Pipeline, individual steps may be replaced using set_params, and ignored by setting to None:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined.set_params(kernel_pca=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
